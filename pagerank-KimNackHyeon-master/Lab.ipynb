{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import pickle\n",
    "from pprint import pprint \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from data.make_casting_graph import oneway_to_bidirected_graph\n",
    "from scipy.sparse import csc_matrix\n",
    "import time\n",
    "from pagerank import pagerank\n",
    "from sklearn.preprocessing import normalize\n",
    "from pyvis.network import Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create idx to num comments\n",
    "with open('./data/ratings.csv', encoding='utf-8') as f:\n",
    "    docs = [line.strip().split(',') for line in f.readlines()[1:]]\n",
    "    _idx2numcomments = {movie_idx:int(num) for num, movie_idx in docs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pre defined casting weight graph\n",
    "with open('./data/casting_graph.pkl', 'rb') as f:\n",
    "    graph = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create idx to actor name function\n",
    "with open('./data/actors.csv', encoding='utf-8') as f:\n",
    "    next(f)\n",
    "    docs = [line.split(',') for line in f.readlines()[1:]]\n",
    "    # English name if exist else Korean name\n",
    "    _idx2actor = {doc[0]:doc[1] for doc in docs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('./data/movies.csv', encoding='utf-8') as f:\n",
    "    next(f)\n",
    "    docs = [line.split(',') for line in f.readlines()[1:]]\n",
    "    _idx2movie = {doc[0]:doc[1] for doc in docs if len(docs)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idx2movie = lambda idx: _idx2movie.get(idx, 'Unknown')\n",
    "idx2actor = lambda idx: _idx2actor.get(idx, 'Unknown')\n",
    "idx2numcomments = lambda idx: _idx2numcomments.get(idx,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g = oneway_to_bidirected_graph(graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [실습 1] 리뷰가 많은 영화 순위"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "기생충 40\n",
      "극한직업 15\n",
      "마약왕 15\n",
      "인터스텔라 14\n",
      "어벤져스: 엔드게임 12\n",
      "걸캅스 12\n",
      "마녀 12\n",
      "택시운전사 11\n",
      "배심원들 11\n",
      "신과함께-죄와 벌 11\n"
     ]
    }
   ],
   "source": [
    "for movie in sorted(_idx2numcomments.items(), key=lambda x: x[1], reverse=True)[:10]:\n",
    "    print(idx2movie(movie[0]),movie[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [실습 2] Dict를 이용한 PageRank "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_graph(casting_csv_path):\n",
    "    # load file\n",
    "    with open(casting_csv_path, encoding='utf-8') as f:\n",
    "        next(f)\n",
    "        graph = {line.split('\\t')[0]:line.split('\\t')[1].strip().split() for line in f if len(line.split('\\t'))==2}\n",
    "    # weighting\n",
    "    # casting order (n-i)^2/ sum (i^2 for i = 1 to n)\n",
    "    def weight(casting_order):\n",
    "        if not casting_order:\n",
    "            return {}\n",
    "        n = len(casting_order)\n",
    "        weights = [(n-i) ** 2 for i in range(n)]\n",
    "        sum_ = sum(weights)\n",
    "        return {actor:w/sum_ for actor, w in zip(casting_order, weights)}\n",
    "    \n",
    "    graph = {movie:weight(actors) for movie, actors in graph.items() if actors}\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pagerank(G, bias=None, df=0.15,\n",
    "             max_iter=50, converge_error=0.001,verbose=0):\n",
    "    \"\"\"\n",
    "    Arguments\n",
    "    ---------\n",
    "    G: Inbound graph, dict of dict\n",
    "        G[to_node][from_node] = weight (float)\n",
    "    df: damping factor, float. default 0.15\n",
    "    \"\"\"\n",
    "    \n",
    "    A, nodes = _normalize(G)\n",
    "    N = len(nodes) # number of nodes\n",
    "    sr = 1 - df # survival rate (1 -  damping factor)\n",
    "    ir = 1 / N # initial rank\n",
    "\n",
    "    # Initialization\n",
    "    rank = {n:ir for n in nodes}\n",
    "\n",
    "    # Initialization of bias\n",
    "    if not bias:\n",
    "        bias = {node:ir for node in nodes}\n",
    "\n",
    "    # Iteration\n",
    "    for _iter in range(1, max_iter + 1):\n",
    "        rank_new = {}\n",
    "\n",
    "        # t: to node, f: from node, w: weight\n",
    "        for t in nodes:\n",
    "            f_dict = A.get(t, {})\n",
    "            rank_t = sum((w*rank[f] for f, w in f_dict.items())) if f_dict else 0\n",
    "            rank_t = sr * rank_t + df * bias.get(t, 0)\n",
    "            rank_new[t] = rank_t\n",
    "\n",
    "        # convergence check\n",
    "        diff = sum((abs(rank[n] - rank_new[n]) for n in nodes))\n",
    "        if diff < converge_error:\n",
    "            if verbose:\n",
    "                print('Early stopped at iter = {}'.format(_iter))\n",
    "            break\n",
    "\n",
    "        if verbose:\n",
    "            sum_ = sum(rank_new.values())\n",
    "            print('Iteration = {}, diff = {}, sum = {}'.format(_iter, diff, sum_))\n",
    "\n",
    "        rank = rank_new\n",
    "\n",
    "    return rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _normalize(G):\n",
    "    \"\"\"It returns outbound normalized graph\n",
    "    Arguments\n",
    "    ---------\n",
    "    G: inbound graph dict of dict\n",
    "    \"\"\"\n",
    "    # Sum of outbound weight\n",
    "    # t: to node, f: from node, w: weight\n",
    "    W_sum = {}    \n",
    "    for t, f_dict in G.items():\n",
    "        for f, w in f_dict.items():\n",
    "            W_sum[f] = W_sum.get(f, 0) + w\n",
    "    A = {t:{f:w/W_sum[f] for f,w in f_dict.items()} for t, f_dict in G.items()}    \n",
    "    nodes = set(G.keys())\n",
    "    nodes.update(W_sum)\n",
    "    return A, nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration = 1, diff = 0.6745935594038686, sum = 1.0000000000000038\n",
      "Iteration = 2, diff = 0.5133755765513058, sum = 1.000000000000008\n",
      "Iteration = 3, diff = 0.4070843471025291, sum = 1.0000000000000095\n",
      "Iteration = 4, diff = 0.32881145690448665, sum = 1.0000000000000033\n",
      "Iteration = 5, diff = 0.26900006261697335, sum = 1.0000000000000093\n",
      "Iteration = 6, diff = 0.2217292304456657, sum = 0.9999999999999902\n",
      "Iteration = 7, diff = 0.1837276549699302, sum = 0.9999999999999943\n",
      "Iteration = 8, diff = 0.15290648077655516, sum = 1.0000000000000042\n",
      "Iteration = 9, diff = 0.12756391624362123, sum = 0.9999999999999927\n",
      "Iteration = 10, diff = 0.10676563571706404, sum = 0.9999999999999943\n",
      "Iteration = 11, diff = 0.08947335545631475, sum = 1.0000000000000067\n",
      "Iteration = 12, diff = 0.07517014319662865, sum = 1.000000000000009\n",
      "Iteration = 13, diff = 0.0631852881114482, sum = 0.9999999999999932\n",
      "Iteration = 14, diff = 0.053206090978406645, sum = 0.9999999999999907\n",
      "Iteration = 15, diff = 0.04483047792706733, sum = 1.0000000000000078\n",
      "Iteration = 16, diff = 0.03781085146468676, sum = 1.000000000000008\n",
      "Iteration = 17, diff = 0.03191234729017597, sum = 1.0000000000000018\n",
      "Iteration = 18, diff = 0.026947257238086587, sum = 1.0000000000000029\n",
      "Iteration = 19, diff = 0.022770184062896107, sum = 1.0000000000000082\n",
      "Iteration = 20, diff = 0.01924796744658077, sum = 1.0000000000000002\n",
      "Iteration = 21, diff = 0.016277037274941494, sum = 0.9999999999999999\n",
      "Iteration = 22, diff = 0.013770288868780683, sum = 0.999999999999998\n",
      "Iteration = 23, diff = 0.011652758751255293, sum = 0.9999999999999947\n",
      "Iteration = 24, diff = 0.009864207584992443, sum = 1.0000000000000022\n",
      "Iteration = 25, diff = 0.008351860248972044, sum = 1.0000000000000033\n",
      "Iteration = 26, diff = 0.007073923041220982, sum = 0.9999999999999973\n",
      "Iteration = 27, diff = 0.005992222715457394, sum = 1.0000000000000007\n",
      "Iteration = 28, diff = 0.005077294242177094, sum = 0.999999999999998\n",
      "Iteration = 29, diff = 0.004302804710051071, sum = 0.9999999999999992\n",
      "Iteration = 30, diff = 0.0036469409233534835, sum = 0.9999999999999931\n",
      "computation time :  0.23241925239562988\n"
     ]
    }
   ],
   "source": [
    "bias = {node:(idx2numcomments(node.split()[1]) if node[0] == 'm' else 0 ) for node in g}\n",
    "_sum = sum(bias.values())\n",
    "bias = {node:b / _sum for node, b in bias.items()}\n",
    "\n",
    "starttime = time.time()\n",
    "rank_dict = pagerank(g,bias=bias,df=0.15,max_iter=30,converge_error=0.001,verbose=1)\n",
    "print(\"computation time : \", (time.time() - starttime))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [실습 3] Numpy를 이용한 PageRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import csc_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6154,)\n",
      "(6154, 6154)\n"
     ]
    }
   ],
   "source": [
    "#node index\n",
    "nodes = set(g.keys())\n",
    "idx2node = list(sorted(nodes))\n",
    "node2idx = {node:idx for idx, node in enumerate(idx2node)}\n",
    "\n",
    "# bias\n",
    "bias = np.asarray([b for node, b in sorted(bias.items(), key=lambda tp:node2idx[tp[0]])])\n",
    "print(bias.shape)\n",
    "\n",
    "# transform g to sparse matrix\n",
    "rows = []\n",
    "cols = []\n",
    "data = []\n",
    "\n",
    "for from_node, to_dict in g.items():\n",
    "    from_idx = node2idx[from_node]\n",
    "    for to_node, weight in to_dict.items():\n",
    "        to_idx = node2idx[to_node]\n",
    "        rows.append(from_idx)\n",
    "        cols.append(to_idx)\n",
    "        data.append(weight)\n",
    "A = csc_matrix((data, (rows, cols)))\n",
    "print(A.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 1 : diff = 0.1685245368865779\n",
      "iter 2 : diff = 0.123534416788289\n",
      "iter 3 : diff = 0.11717242074154521\n",
      "iter 4 : diff = 0.08676250638774644\n",
      "iter 5 : diff = 0.08106650827175174\n",
      "iter 6 : diff = 0.06044614044638538\n",
      "iter 7 : diff = 0.05589952786903922\n",
      "iter 8 : diff = 0.04188475454126574\n",
      "iter 9 : diff = 0.038452782327255894\n",
      "iter 10 : diff = 0.0289095171904886\n",
      "iter 11 : diff = 0.026405522194198443\n",
      "iter 12 : diff = 0.01994486388644759\n",
      "iter 13 : diff = 0.01811137289916391\n",
      "iter 14 : diff = 0.013753287448751986\n",
      "iter 15 : diff = 0.012408911428306675\n",
      "iter 16 : diff = 0.009469243738374537\n",
      "iter 17 : diff = 0.008494000468005527\n",
      "iter 18 : diff = 0.006511648928942716\n",
      "iter 19 : diff = 0.005809774127703195\n",
      "iter 20 : diff = 0.004473307017566352\n",
      "iter 21 : diff = 0.0039712967053357525\n",
      "iter 22 : diff = 0.0030704578506105173\n",
      "iter 23 : diff = 0.0027152845982687866\n",
      "iter 24 : diff = 0.002106149459828414\n",
      "iter 25 : diff = 0.0018577039374234091\n",
      "iter 26 : diff = 0.0014438021951808503\n",
      "iter 27 : diff = 0.0012704561426783514\n",
      "iter 28 : diff = 0.0009892576559651914\n",
      "iter 29 : diff = 0.0008685536766681317\n",
      "iter 30 : diff = 0.000677506241060136\n",
      "computation time :  0.007168292999267578\n"
     ]
    }
   ],
   "source": [
    "max_iter = 30\n",
    "df = 0.85\n",
    "\n",
    "ir = 1 / A.shape[0]\n",
    "rank_num = np.asarray([ir] * A.shape[0])\n",
    "\n",
    "starttime = time.time()\n",
    "\n",
    "for n_iter in range(1 , max_iter + 1):\n",
    "    rank_new = A.dot(rank_num)\n",
    "    rank_new = normalize(rank_new.reshape(1,-1) , norm='l1').reshape(-1)\n",
    "    rank_new = df * rank_new + (1-df) * bias\n",
    "    diff = abs(rank_num - rank_new).sum()\n",
    "    rank_num = rank_new\n",
    "    print('iter {} : diff = {}'.format(n_iter , diff))\n",
    "    \n",
    "print(\"computation time : \", (time.time() - starttime))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [과제 2] 영화 Top 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "movie_rank = {}\n",
    "for key, val in rank_dict.items():\n",
    "    if 'movie' in key:\n",
    "        movie_rank[key] = val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "movie_rank =sorted(movie_rank.items(), key=lambda t : t[1],reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========dict를 이용한 방식==========\n",
      "161967 , 기생충 , 0.0032033878121671224\n",
      "167651 , 극한직업 , 0.0014303471787626468\n",
      "175322 , 마녀 , 0.0011565783119412997\n",
      "156464 , 보헤미안 랩소디 , 0.0011527961465662747\n",
      "130966 , 부산행 , 0.001098819013448319\n",
      "177483 , 배심원들 , 0.0009469824923736168\n",
      "174065 , 걸캅스 , 0.0009354687095915042\n",
      "37886 , 클레멘타인 , 0.000918249213245038\n",
      "154449 , 리틀 포레스트 , 0.00091821747845663\n",
      "163788 , 알라딘 , 0.0007997936563664337\n"
     ]
    }
   ],
   "source": [
    "print(\"==========dict를 이용한 방식==========\")\n",
    "for i in range(10):\n",
    "    movieId = movie_rank[i][0][6:]\n",
    "    movieName = _idx2movie[movieId]\n",
    "    rankpoint = movie_rank[i][1]\n",
    "    print(movieId, ',', movieName, ',', rankpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========numpy를 이용한 방식==========\n",
      "161967 , 기생충 , 0.0015437432925532173\n",
      "156464 , 보헤미안 랩소디 , 0.0010864984266341052\n",
      "175322 , 마녀 , 0.0008946794759721638\n",
      "174065 , 걸캅스 , 0.0008564445054703045\n",
      "167651 , 극한직업 , 0.0007648489380972874\n",
      "37886 , 클레멘타인 , 0.000728929546919159\n",
      "157297 , 마약왕 , 0.0007133104346250872\n",
      "71509 , 아저씨 , 0.0006938076365826392\n",
      "136900 , 어벤져스: 엔드게임 , 0.0006567566198412949\n",
      "163788 , 알라딘 , 0.000638759850450271\n"
     ]
    }
   ],
   "source": [
    "rank_ = {idx2node[idx]:value for idx, value in enumerate(rank_num)}\n",
    "movierank = {node:value for node, value in rank_.items() if 'movie' in node}\n",
    "actorrank = {node:value for node, value in rank_.items() if 'actor' in node}\n",
    "movierank = sorted(movierank.items(), key=lambda x: x[1],reverse=True)\n",
    "print(\"==========numpy를 이용한 방식==========\")\n",
    "for movie, value in movierank[:10]:\n",
    "    movie_idx = movie.split()[1]\n",
    "    print(movie_idx, ',', idx2movie(movie_idx), ',', value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [과제 3] 영화 Top 10 노드 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "got_net = Network(height=\"750px\", width=\"100%\", bgcolor=\"#ffffff\", font_color=\"black\")\n",
    "got_net.barnes_hut()\n",
    "\n",
    "f = open(\"./data/casting.txt\", 'r')\n",
    "\n",
    "while True:\n",
    "    line = f.readline()\n",
    "    if not line: break\n",
    "    spl = line.split('\\t')\n",
    "    for i in movie_rank[:10]:\n",
    "        movieId = spl[0]\n",
    "        actorList = spl[1].split(' ')\n",
    "        del actorList[-1]\n",
    "        if spl[0] == i[0][6:] :\n",
    "            got_net.add_node(movieId, label=_idx2movie[movieId])\n",
    "            for j in actorList:\n",
    "                got_net.add_node(j, label=_idx2actor[j])\n",
    "                got_net.add_edge(movieId,j)\n",
    "                \n",
    "                f2 = open(\"./data/casting.txt\", 'r')\n",
    "                \n",
    "                while True:\n",
    "                    line = f2.readline()\n",
    "                    if not line: break\n",
    "                    spl = line.split('\\t')\n",
    "                    actorList = spl[1].split(' ')\n",
    "                    for actor_index in actorList:\n",
    "                        if j == actor_index:\n",
    "                            got_net.add_node(spl[0], label=_idx2movie[spl[0]])\n",
    "                            got_net.add_edge(spl[0],j)\n",
    "\n",
    "got_net.show(\"dict_graph.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "got_net = Network(height=\"750px\", width=\"100%\", bgcolor=\"#ffffff\", font_color=\"black\")\n",
    "got_net.barnes_hut()\n",
    "\n",
    "f = open(\"./data/casting.txt\", 'r')\n",
    "\n",
    "while True:\n",
    "    line = f.readline()\n",
    "    if not line: break\n",
    "    spl = line.split('\\t')\n",
    "    for i in movierank[:10]:\n",
    "        movieId = spl[0]\n",
    "        actorList = spl[1].split(' ')\n",
    "        del actorList[-1]\n",
    "        if spl[0] == i[0][6:] :\n",
    "            got_net.add_node(movieId, label=_idx2movie[movieId])\n",
    "            for j in actorList:\n",
    "                got_net.add_node(j, label=_idx2actor[j])\n",
    "                got_net.add_edge(movieId,j)\n",
    "                \n",
    "                f2 = open(\"./data/casting.txt\", 'r')\n",
    "                \n",
    "                while True:\n",
    "                    line = f2.readline()\n",
    "                    if not line: break\n",
    "                    spl = line.split('\\t')\n",
    "                    actorList = spl[1].split(' ')\n",
    "                    for actor_index in actorList:\n",
    "                        if j == actor_index:\n",
    "                            got_net.add_node(spl[0], label=_idx2movie[spl[0]])\n",
    "                            got_net.add_edge(spl[0],j)\n",
    "\n",
    "got_net.show(\"numpy_graph.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
